####################################
# The following are general settings
####################################
# Experiment name, more details are in [Experiment Name Convention]. If debug in the experiment name, it will enter debug mode
name: ESRGAN_x2_f64b16_UCML_1000k_B16G1_wandb
model_type: ESRGANModel
scale: 2
num_gpu: 1  # set num_gpu: 0 for cpu mode
manual_seed: 0

########################################################
# The following are the dataset and data loader settings
########################################################
datasets:
  train:
    name: UCMerced_LandUse
    type: PairedImageDataset
    dataroot_gt: Data/UCMerced_LandUse/train
    # LQ (Low-Quality) folder path
    dataroot_lq: Data/UCMerced_LandUse/train_downx2
    filename_tmpl: '{}'
    io_backend:
      type: disk

    # Ground-Truth training patch size
    gt_size: 128
    # Whether to use horizontal flip. Here, flip is for horizontal flip
    use_flip: true
    # Whether to rotate. Here for rotations with every 90 degree
    use_rot: true

    #### The following are data loader settings
    # Whether to shuffle
    use_shuffle: true
    num_worker_per_gpu: 4
    batch_size_per_gpu: 16
    dataset_enlarge_ratio: 100
    prefetch_mode: ~

  val:
    name: UCMerced_LandUse
    type: PairedImageDataset
    dataroot_gt: Data/UCMerced_LandUse/val
    dataroot_lq: Data/UCMerced_LandUse/val_downx2
    io_backend:
      type: disk

##################################################
# The following are the network structure settings
##################################################
network_g:
  type: RRDBNet # Architecture type.
  num_in_ch: 3 # Channel number of inputs
  num_out_ch: 3 # Channel number of outputs
  num_feat: 64 # Channel number of middle features
  num_block: 23

network_d:
  type: VGGStyleDiscriminator128
  num_in_ch: 3
  num_feat: 64

#########################################################
# The following are path, pretraining and resume settings
#########################################################
path:
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~


#####################################
# The following are training settings
#####################################
train:
  # Optimizer settings
  optim_g:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  optim_d:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [ 0.9, 0.99 ]

  # Learning rate scheduler settings
  scheduler:
    type: MultiStepLR
    milestones: [ 50000, 100000, 200000, 300000 ]
    gamma: 0.5

  # Total iterations for training
  total_iter: 400000
  warmup_iter: -1 # no warm up

  #### The following are loss settings
  # Pixel-wise loss options
  pixel_opt:
    # Loss type. Usually the class name defined in the `basicsr/models/losses` folder
    type: L1Loss
    loss_weight: !!float 1e-2
    reduction: mean
  perceptual_opt:
    type: PerceptualLoss
    layer_weights:
      'conv5_4': 1  # before relu
    vgg_type: vgg19
    use_input_norm: true
    range_norm: false
    perceptual_weight: 1.0
    style_weight: 0
    criterion: l1
  gan_opt:
    type: GANLoss
    gan_type: vanilla
    real_label_val: 1.0
    fake_label_val: 0.0
    loss_weight: !!float 5e-3

  net_d_iters: 1
  net_d_init_iters: 0


#######################################
# The following are validation settings
#######################################
val:
  val_freq: !!float 5e3
  save_img: true

  # Metrics in validation
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 4
      test_y_channel: false

########################################
# The following are the logging settings
########################################
logger:
  # Logger frequency
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

################################################
# The following are distributed training setting
# Only require for slurm training
################################################
dist_params:
  backend: nccl
  port: 29500
